{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\", header=None, \n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')\n",
    "\n",
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 61.8812\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 942us/step - loss: 12.0424\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 894us/step - loss: 8.8556\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 8.2839\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 971us/step - loss: 7.7650\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 865us/step - loss: 7.3462\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 951us/step - loss: 7.0392\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 884us/step - loss: 6.8098\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 913us/step - loss: 6.6533\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.5421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26cc4912488>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())\n",
    "\n",
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 913us/step - loss: 94.3748\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 913us/step - loss: 55.1997\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 17.5221\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.1457\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 5.1811\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 5.0960\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 5.0657\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 942us/step - loss: 5.0298\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 894us/step - loss: 5.0141\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 5.0206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26cc61a76c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "normalize = preprocessing.Normalization()\n",
    "normalize.adapt(abalone_features)\n",
    "\n",
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# titanic\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'AddV2:0' shape=(None,) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')\n",
    "\n",
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Do a calculation using is\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "calc = tf.keras.Model(inputs=input, outputs=result)\n",
    "\n",
    "print(calc(1).numpy())\n",
    "print(calc(2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <tf.Tensor 'sex:0' shape=(None, 1) dtype=string>,\n",
       " 'age': <tf.Tensor 'age:0' shape=(None, 1) dtype=float32>,\n",
       " 'n_siblings_spouses': <tf.Tensor 'n_siblings_spouses:0' shape=(None, 1) dtype=float32>,\n",
       " 'parch': <tf.Tensor 'parch:0' shape=(None, 1) dtype=float32>,\n",
       " 'fare': <tf.Tensor 'fare:0' shape=(None, 1) dtype=float32>,\n",
       " 'class': <tf.Tensor 'class:0' shape=(None, 1) dtype=string>,\n",
       " 'deck': <tf.Tensor 'deck:0' shape=(None, 1) dtype=string>,\n",
       " 'embark_town': <tf.Tensor 'embark_town:0' shape=(None, 1) dtype=string>,\n",
       " 'alone': <tf.Tensor 'alone:0' shape=(None, 1) dtype=string>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  building a set of symbolic\n",
    "\n",
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "\n",
    "    inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'normalization_1/truediv:0' shape=(None, 4) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "for name, input in inputs.items():\n",
    "    if input.dtype == tf.float32:\n",
    "        continue\n",
    "\n",
    "    lookup = preprocessing.StringLookup(vocabulary=np.unique(titanic_features[name])) # map from strings to integer indices in a vocabulary\n",
    "    one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size()) # convert the indexes into float32 data appropriate for the model.\n",
    "\n",
    "    x = lookup(input)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)\n",
    "    \n",
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5926\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5235\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4859\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4601\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4449\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4347\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4288\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4251\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4237\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4215\n",
      "WARNING:tensorflow:From C:\\Users\\Noam\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Noam\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: test\\assets\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x0000026CCBBF8C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor([[-2.024]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-2.024]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "titanic_features_dict = {name: np.array(value) for name, value in titanic_features.items()}\n",
    "\n",
    "def titanic_model(preprocessing_head, inputs):\n",
    "    body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "\n",
    "    model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam())\n",
    "    return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)\n",
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)\n",
    "\n",
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')\n",
    "\n",
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "    for i in itertools.count():\n",
    "        # For each feature take index `i`\n",
    "        example = {name:values[i] for name, values in features.items()}\n",
    "        yield example\n",
    "        \n",
    "for example in slices(titanic_features_dict):\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : b'male'\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : b'Third'\n",
      "deck               : b'unknown'\n",
      "embark_town        : b'Southampton'\n",
      "alone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)\n",
    "for example in features_ds:\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4226\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4209\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4197\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4200\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26cc7dd4d88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))\n",
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)\n",
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 3us/step\n",
      "sex                 : [b'female' b'male' b'male' b'male' b'female']\n",
      "age                 : [60. 28. 28. 28. 23.]\n",
      "n_siblings_spouses  : [1 0 0 0 0]\n",
      "parch               : [0 0 0 0 0]\n",
      "fare                : [75.25  56.496  8.05   7.896  7.55 ]\n",
      "class               : [b'First' b'Third' b'Third' b'Third' b'Third']\n",
      "deck                : [b'D' b'unknown' b'unknown' b'unknown' b'unknown']\n",
      "embark_town         : [b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton']\n",
      "alone               : [b'n' b'y' b'y' b'y' b'y']\n",
      "\n",
      "label               : [1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# single file\n",
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "\n",
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)\n",
    "\n",
    "for batch, label in titanic_csv_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "    print()\n",
    "    print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
      "409600/405373 [==============================] - 1s 4us/step\n",
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                : [293.07 281.81 291.77 280.25 261.  ]\n",
      "rain_1h             : [0. 0. 0. 0. 0.]\n",
      "snow_1h             : [0. 0. 0. 0. 0.]\n",
      "clouds_all          : [88 90 75 20  1]\n",
      "weather_main        : [b'Thunderstorm' b'Clouds' b'Clouds' b'Clouds' b'Clear']\n",
      "weather_description : [b'proximity thunderstorm' b'overcast clouds' b'broken clouds'\n",
      " b'few clouds' b'sky is clear']\n",
      "date_time           : [b'2013-06-29 20:00:00' b'2012-10-11 21:00:00' b'2012-10-04 21:00:00'\n",
      " b'2012-11-01 13:00:00' b'2013-03-21 10:00:00']\n",
      "\n",
      "label               : [3250 2679 2822 5189 4433]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')\n",
    "\n",
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value[:5]}\")\n",
    "    print()\n",
    "    print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n",
      "160317440/160313983 [==============================] - 80s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['fonts\\\\AGENCY.csv',\n",
       "  'fonts\\\\ARIAL.csv',\n",
       "  'fonts\\\\BAITI.csv',\n",
       "  'fonts\\\\BANKGOTHIC.csv',\n",
       "  'fonts\\\\BASKERVILLE.csv',\n",
       "  'fonts\\\\BAUHAUS.csv',\n",
       "  'fonts\\\\BELL.csv',\n",
       "  'fonts\\\\BERLIN.csv',\n",
       "  'fonts\\\\BERNARD.csv',\n",
       "  'fonts\\\\BITSTREAMVERA.csv'],\n",
       " 153)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple files\n",
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True)\n",
    "\n",
    "import pathlib\n",
    "font_csvs =  sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10], len(font_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'ONYX' b'CAMBRIA' b'CORBEL' b'CAMBRIA' b'BASKERVILLE' b'PALACE'\n",
      " b'SCRIPT' b'CAMBRIA' b'GUNPLAY' b'CENTURY']\n",
      "fontVariant         : [b'ONYX' b'CAMBRIA' b'CORBEL' b'CAMBRIA' b'BASKERVILLE OLD FACE'\n",
      " b'PALACE SCRIPT MT' b'SCRIPTS' b'CAMBRIA' b'GUNPLAY'\n",
      " b'CENTURY SCHOOLBOOK']\n",
      "m_label             : [   62 10900   350 10844    97    80   261 10794   190   937]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [1 0 0 0 0 1 1 0 0 0]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [46 27 39 45 51 29 67 63 31 37]\n",
      "m_left              : [28 25 24 22 22 23 25 25 21 22]\n",
      "originalH           : [24 72 61 39 28 37 28 17 48 49]\n",
      "originalW           : [29 40 29 36 27 51 40 40 43 48]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1 220   1   1   1   1   1 255  31   1]\n",
      "r0c1                : [  1 185   1   1   1   1   1 255 164   1]\n",
      "r0c2                : [  1 114   2   1  57   1   1 255 255   1]\n",
      "r0c3                : [  1  78  51   1  73   1   1 255 137   1]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)\n",
    "\n",
    "for features in fonts_ds.take(1):\n",
    "    for i, (name, value) in enumerate(features.items()):\n",
    "        if i>15:\n",
    "            break\n",
    "        print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low level functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()]*10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=all_strings) \n",
    "\n",
    "for f in features:\n",
    "    print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: int32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=titanic_types) \n",
    "\n",
    "for f in features:\n",
    "    print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n",
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n",
    "\n",
    "for example in simple_titanic.take(1):\n",
    "    print([e.numpy() for e in example])\n",
    "    \n",
    "##\n",
    "\n",
    "def decode_titanic_line(line):\n",
    "    return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    # Load the lines of text\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    # Skip the header row.\n",
    "    .skip(1)\n",
    "    # Decode the line.\n",
    "    .map(decode_titanic_line)\n",
    ")\n",
    "\n",
    "for example in manual_titanic.take(1):\n",
    "    print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n",
      "fonts\\AGENCY.csv\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "Epoch 1:\n",
      "     b'fonts\\\\YI BAITI.csv'\n",
      "     b'fonts\\\\TREBUCHET.csv'\n",
      "     b'fonts\\\\BAUHAUS.csv'\n",
      "     b'fonts\\\\CENTURY.csv'\n",
      "     b'fonts\\\\TW.csv'\n",
      "    ...\n",
      "\n",
      "Epoch 2:\n",
      "     b'fonts\\\\CASTELLAR.csv'\n",
      "     b'fonts\\\\GABRIOLA.csv'\n",
      "     b'fonts\\\\BELL.csv'\n",
      "     b'fonts\\\\MYANMAR.csv'\n",
      "     b'fonts\\\\KRISTEN.csv'\n",
      "    ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>font_name</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMBRIA</td>\n",
       "      <td>︀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GABRIOLA</td>\n",
       "      <td>ﬅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAMBRIA</td>\n",
       "      <td>ﬄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GABRIOLA</td>\n",
       "      <td>ﬄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAMBRIA</td>\n",
       "      <td>ﬃ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GABRIOLA</td>\n",
       "      <td>ﬃ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAMBRIA</td>\n",
       "      <td>ﬂ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  font_name character\n",
       "0   CAMBRIA         ︀\n",
       "1  GABRIOLA         ﬅ\n",
       "2     MONEY         2\n",
       "3   CAMBRIA         ﬄ\n",
       "4  GABRIOLA         ﬄ\n",
       "5     MONEY         2\n",
       "6   CAMBRIA         ﬃ\n",
       "7  GABRIOLA         ﬃ\n",
       "8     MONEY         0\n",
       "9   CAMBRIA         ﬂ"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple files\n",
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)\n",
    "\n",
    "num_font_features = font_line.count(',')+1\n",
    "font_column_types = [str(), str()] + [float()]*(num_font_features-2)\n",
    "\n",
    "print(font_csvs[0])\n",
    "\n",
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)\n",
    "\n",
    "for row in simple_font_ds.take(10):\n",
    "    print(row[0].numpy())\n",
    "    \n",
    "font_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "\n",
    "##\n",
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "\n",
    "##\n",
    "def make_font_csv_ds(path):\n",
    "    return tf.data.experimental.CsvDataset(path, record_defaults=font_column_types, header=True)\n",
    "\n",
    "font_rows = font_files.interleave(make_font_csv_ds, cycle_length=3)\n",
    "\n",
    "fonts_dict = {'font_name':[], 'character':[]}\n",
    "\n",
    "for row in font_rows.take(10):\n",
    "    fonts_dict['font_name'].append(row[0].numpy().decode())\n",
    "    fonts_dict['character'].append(chr(row[2].numpy()))\n",
    "\n",
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset( file_pattern = \"fonts/*.csv\", batch_size=BATCH_SIZE, num_epochs=1, num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_ds.take(20)):\n",
    "    print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "Wall time: 4.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_fast.take(20)):\n",
    "    print('.',end='')\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
